{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# [Project Title]\n",
    "\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "\n",
    "- 1: Scope the Project and Gather Data\n",
    "- 2: Explore and Assess the Data\n",
    "- 3: Define the Data Model\n",
    "- 4: Run ETL to Model the Data\n",
    "- 5: Complete Project Write Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path: str = \"../src\"\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import extract_sas_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path: Path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "### 1. Scope the Project and Gather Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Scope\n",
    "\n",
    "_Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>_\n",
    "\n",
    "**The goal of this project is to find possible correlations between inmigrants destinations, the city demographics, the availability of airports in those destinations and its average yearly temperature.**\n",
    "\n",
    "**Execution plan:**\n",
    "\n",
    "1. Data is uploaded to S3 buckets.\n",
    "2. Data is extracted, transformed and loaded (ETL) into a Redshift Database through an Airflow DAG.\n",
    "   1. Airflow DAG uses operators that use Spark, run on EMR (if possible at all, seems a bit complicated).\n",
    "3. Analytics queries are run to answer questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Describe and Gather Data\n",
    "\n",
    "The following datasets are included in the project:\n",
    "\n",
    "- **I94 Immigration Data**: This data comes from the US National Tourism and Trade Office. A data dictionary\n",
    "- **World Temperature Data**: ...\n",
    "- **U.S. City Demographic Data**: ...\n",
    "- **Airport Code Table**: This is a simple table of airport codes and corresponding cities...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_file = data_path.joinpath(\n",
    "    \"i94_inmigration_data_2016/I94_SAS_Labels_Descriptions.SAS\"\n",
    ")\n",
    "\n",
    "sas_file_content = sas_file.read_text().replace(\"\\t\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "x = re.findall(r\"value [^;]*\", sas_file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = data_path.joinpath(\"i94_inmigration_data_2016/data_sample.csv\")\n",
    "pd.read_csv(file_path).to_csv(file_path.with_suffix(\".csv.bz2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_file_content.split(\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Datasets preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.1. I94 Immigration Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94_df = pd.read_csv(\n",
    "    data_path.joinpath(\"i94_inmigration_data_2016\").joinpath(\"data_sample.csv\"),\n",
    "    index_col=0,\n",
    ")\n",
    "print(i94_df.columns)\n",
    "i94_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.2. World Temperature Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv(\n",
    "    data_path.joinpath(\"global_land_temperature_by_city.csv\"),\n",
    "    index_col=0,\n",
    ").dropna(subset=[\"AverageTemperature\"])\n",
    "print(temp_df.columns)\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.value_counts([\"City\", \"Country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.3. U.S. City Demographic Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_dem_df = pd.read_csv(data_path.joinpath(\"us_cities_demographics.csv\"), sep=\";\")\n",
    "print(us_dem_df.columns)\n",
    "us_dem_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.4. Airport Codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airp_df = pd.read_csv(data_path.joinpath(\"airport_codes.csv\"), index_col=0)\n",
    "print(airp_df.columns)\n",
    "airp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.config(\n",
    "        \"spark.jars.repositories\", \"https://repos.spark-packages.org/\"\n",
    "    )\n",
    "    .config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "df_spark = spark.read.format(\"com.github.saurfang.sas.spark\").load(\n",
    "    \"../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write to parquet\n",
    "df_spark.write.parquet(\"sas_data\")\n",
    "df_spark = spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "\n",
    "#### Explore the Data\n",
    "\n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "\n",
    "Document steps necessary to clean the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "List the steps necessary to pipeline the data into the chosen data model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data\n",
    "\n",
    "#### 4.1 Create the data model\n",
    "\n",
    "Build the data pipelines to create the data model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    "\n",
    "- Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    "- Unit tests for the scripts to ensure they are doing the right thing\n",
    "- Source/Count checks to ensure completeness\n",
    "\n",
    "Run Quality Checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary\n",
    "\n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "\n",
    "- Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "- Propose how often the data should be updated and why.\n",
    "- Write a description of how you would approach the problem differently under the following scenarios:\n",
    "- The data was increased by 100x.\n",
    "- The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "- The database needed to be accessed by 100+ people.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('de_capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c6ab47c24cf80276cd6370728e56e74687e2bfe799d1173d929047132a801f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
