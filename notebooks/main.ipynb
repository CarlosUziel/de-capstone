{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Engineering Capstone Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path: str = \"../src\"\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import process_config\n",
    "from utils.spark import create_spark_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path: Path = Path(\"../data\")\n",
    "user_config, dl_config = (\n",
    "    process_config(Path(os.getcwd()).parent.joinpath(\"_user.cfg\")),\n",
    "    process_config(Path(os.getcwd()).parent.joinpath(\"dl.cfg\")),\n",
    ")\n",
    "spark = create_spark_session(user_config, dl_config)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## 1. Data preview and exploration\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. I94 Immigration Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94_df = pd.read_csv(\n",
    "    data_path.joinpath(\"i94_inmigration_data_2016\").joinpath(\"data_sample.csv.bz2\"),\n",
    "    index_col=0,\n",
    ")\n",
    "print(i94_df.columns)\n",
    "i94_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. World Temperature Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv(\n",
    "    data_path.joinpath(\"global_land_temperature_by_city.csv.bz2\"),\n",
    "    index_col=0,\n",
    ").dropna(subset=[\"AverageTemperature\"])\n",
    "print(temp_df.columns)\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[temp_df[\"Country\"] == \"United States\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. U.S. City Demographic Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_dem_df = pd.read_csv(data_path.joinpath(\"us_cities_demographics.csv.bz2\"))\n",
    "print(us_dem_df.columns)\n",
    "us_dem_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Airport Codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airp_df = pd.read_csv(data_path.joinpath(\"airport_codes.csv.bz2\"), index_col=0)\n",
    "print(airp_df.columns)\n",
    "airp_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airp_df[airp_df[\"iso_country\"] == \"US\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "### Step 2: Explore and Assess the Data\n",
    "\n",
    "#### Explore the Data\n",
    "\n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "\n",
    "Document steps necessary to clean the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "### Step 3: Define the Data Model\n",
    "\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "List the steps necessary to pipeline the data into the chosen data model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "### Step 4: Run Pipelines to Model the Data\n",
    "\n",
    "#### 4.1 Create the data model\n",
    "\n",
    "Build the data pipelines to create the data model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    "\n",
    "- Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    "- Unit tests for the scripts to ensure they are doing the right thing\n",
    "- Source/Count checks to ensure completeness\n",
    "\n",
    "Run Quality Checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary\n",
    "\n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "### Step 5: Complete Project Write Up\n",
    "\n",
    "- Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "- Propose how often the data should be updated and why.\n",
    "- Write a description of how you would approach the problem differently under the following scenarios:\n",
    "- The data was increased by 100x.\n",
    "- The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "- The database needed to be accessed by 100+ people.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('de_capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c6ab47c24cf80276cd6370728e56e74687e2bfe799d1173d929047132a801f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
